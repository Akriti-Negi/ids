{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFHePmZpuurb",
        "outputId": "dfe5651b-a55a-4fc3-c82b-f5d4b0023252"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from docx) (5.4.0)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.11/dist-packages (from docx) (11.2.1)\n",
            "Building wheels for collected packages: docx\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53893 sha256=e136059b30effe152a39097d679f28578c92991a275830b58497f2c9065d83dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/3e/c3/e81c11effd0be5658a035947c66792dd993bcff317eae0e1ed\n",
            "Successfully built docx\n",
            "Installing collected packages: docx\n",
            "Successfully installed docx-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3RT_adQu9SF",
        "outputId": "86956fc0-7eff-4739-fb88-3cb648a0d68b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/244.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from docx import Document\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, GlobalAveragePooling1D, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "#Get Feature Names from .docx"
      ],
      "metadata": {
        "id": "VJnvvhhR7xA9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Load Dataset\n",
        "def load_dataset(name):\n",
        "    if name == \"NSL-KDD\":\n",
        "        url = \"/content/KDDTrain+.txt\"\n",
        "        df = pd.read_csv(url, header=None)\n",
        "\n",
        "        #col_names = get_feature_names_from_docx()\n",
        "        col_names = [\n",
        "    'duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent',\n",
        "    'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root',\n",
        "    'num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login',\n",
        "    'is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate',\n",
        "    'srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count',\n",
        "    'dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate',\n",
        "    'dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate',\n",
        "    'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate',\n",
        "    'class', 'difficulty'\n",
        "]\n",
        "        df.columns = col_names\n",
        "\n",
        "        df.drop_duplicates(inplace=True)\n",
        "        df['class'] = df['class'].apply(lambda x: 'normal' if x == 'normal' else 'attack')\n",
        "\n",
        "    elif name == \"CICIDS2017\":\n",
        "        df = pd.read_csv(\"/content/combine.csv\")  # Provide cleaned CSV locally\n",
        "        columns_to_fix = [' Destination Port']  # Add others if needed\n",
        "        for col in columns_to_fix:\n",
        "          df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "        df.dropna(subset=columns_to_fix, inplace=True)\n",
        "        df['class'] = df[' Label'].apply(lambda x: 'normal' if x == 'BENIGN' else 'attack')\n",
        "        df.drop(columns=[' Label'], inplace=True)\n",
        "\n",
        "    elif name == \"UNSW-NB15\":\n",
        "        df = pd.read_csv(\"/content/UNSW-NB15_1.csv\")  # Provide cleaned CSV locally\n",
        "        df = df.dropna().drop_duplicates()\n",
        "        df['class'] = df['label'].apply(lambda x: 'normal' if x == 0 else 'attack')\n",
        "        df.drop(columns=['label'], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unknown dataset name\")\n",
        "\n",
        "    # Label encode categorical columns\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        if col != 'class':\n",
        "            df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    # Then fill or drop NaNs\n",
        "    df.fillna(df.median(numeric_only=True), inplace=True)\n",
        "    X = df.drop('class', axis=1)\n",
        "    y = LabelEncoder().fit_transform(df['class'])\n",
        "    # Replace infinite values with NaN\n",
        "\n",
        "\n",
        "    # Normalize features\n",
        "    X_scaled = StandardScaler().fit_transform(X)\n",
        "    X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
        "\n",
        "    return train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "7_f1W0P4eEW-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Custom Attention Layer\n",
        "\n",
        "class SelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.query_dense = tf.keras.layers.Dense(d_model)\n",
        "        self.key_dense = tf.keras.layers.Dense(d_model)\n",
        "        self.value_dense = tf.keras.layers.Dense(d_model)\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        weights = self.softmax(score)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output"
      ],
      "metadata": {
        "id": "K1XeKFQQ8NDa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Build Model\n",
        "\n",
        "def build_model(input_shape, num_classes):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    x = Conv1D(64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "    x = SelfAttention(64)(x)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "iyQdsTD58VAD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate\n",
        "\n",
        "def train_and_evaluate(dataset_name):\n",
        "    print(f\"\\nTraining on {dataset_name}...\\n\")\n",
        "\n",
        "    # Load dataset\n",
        "    X_train, X_test, y_train, y_test = load_dataset(dataset_name)\n",
        "\n",
        "    # Number of classes in the dataset\n",
        "    num_classes = len(np.unique(y_train))\n",
        "\n",
        "    # Convert labels to categorical (one-hot encoding)\n",
        "    y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
        "    y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "    # Build model\n",
        "    model = build_model(input_shape=X_train.shape[1:], num_classes=num_classes)\n",
        "\n",
        "    # Model training\n",
        "    model.fit(X_train, y_train_cat, epochs=15, batch_size=128, validation_split=0.1, verbose=1)\n",
        "\n",
        "    # Model prediction\n",
        "    y_pred_probs = model.predict(X_test)  # Probabilities for AUC, etc.\n",
        "    y_pred_classes = np.argmax(y_pred_probs, axis=1)  # Predicted class labels\n",
        "\n",
        "    # Classification Report and Confusion Matrix\n",
        "    print(f\"Classification Report for {dataset_name}:\\n\", classification_report(y_test, y_pred_classes))\n",
        "    print(f\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_classes))\n",
        "\n",
        "    #  Metrics\n",
        "    acc = accuracy_score(y_test, y_pred_classes)\n",
        "    prec = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "    rec = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "    auc = roc_auc_score(y_test_cat, y_pred_probs, multi_class='ovr', average='weighted')  # AUC for multi-class\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred_classes)\n",
        "    FP = cm.sum(axis=0) - np.diag(cm)  # False Positives\n",
        "    FN = cm.sum(axis=1) - np.diag(cm)  # False Negatives\n",
        "    TP = np.diag(cm)  # True Positives\n",
        "    TN = cm.sum() - (FP + FN + TP)  # True Negatives\n",
        "\n",
        "    FPR = FP / (FP + TN + 1e-10)\n",
        "    TNR = TN / (TN + FP + 1e-10)\n",
        "\n",
        "    print(\"\\n Evaluation Metrics:\")\n",
        "    print(f\" Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(f\"AUC:       {auc:.4f}\")\n",
        "    print(f\"Avg FPR:   {np.mean(FPR):.4f}\")\n",
        "    print(f\"Avg TNR:   {np.mean(TNR):.4f}\")\n",
        "\n",
        "#  Run on NSL-KDD\n",
        "train_and_evaluate(\"CICIDS2017\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV09T7c78eMJ",
        "outputId": "fb57b8cb-cec1-400d-90ea-dbc7338fc831"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training on CICIDS2017...\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-1ce4e00fb14b>:25: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"/content/combine.csv\")  # Provide cleaned CSV locally\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 12ms/step - accuracy: 0.9401 - loss: 0.1352 - val_accuracy: 0.9723 - val_loss: 0.0609\n",
            "Epoch 2/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 12ms/step - accuracy: 0.9793 - loss: 0.0497 - val_accuracy: 0.9832 - val_loss: 0.0401\n",
            "Epoch 3/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.0419 - val_accuracy: 0.9830 - val_loss: 0.0393\n",
            "Epoch 4/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 12ms/step - accuracy: 0.9834 - loss: 0.0391 - val_accuracy: 0.9836 - val_loss: 0.0387\n",
            "Epoch 5/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 11ms/step - accuracy: 0.9840 - loss: 0.0374 - val_accuracy: 0.9847 - val_loss: 0.0352\n",
            "Epoch 6/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 12ms/step - accuracy: 0.9844 - loss: 0.0361 - val_accuracy: 0.9850 - val_loss: 0.0346\n",
            "Epoch 7/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 11ms/step - accuracy: 0.9850 - loss: 0.0350 - val_accuracy: 0.9851 - val_loss: 0.0352\n",
            "Epoch 8/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 11ms/step - accuracy: 0.9853 - loss: 0.0344 - val_accuracy: 0.9840 - val_loss: 0.0353\n",
            "Epoch 9/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0341 - val_accuracy: 0.9856 - val_loss: 0.0330\n",
            "Epoch 10/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 11ms/step - accuracy: 0.9855 - loss: 0.0335 - val_accuracy: 0.9859 - val_loss: 0.0319\n",
            "Epoch 11/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 12ms/step - accuracy: 0.9859 - loss: 0.0326 - val_accuracy: 0.9855 - val_loss: 0.0333\n",
            "Epoch 12/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 11ms/step - accuracy: 0.9859 - loss: 0.0326 - val_accuracy: 0.9856 - val_loss: 0.0320\n",
            "Epoch 13/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 11ms/step - accuracy: 0.9860 - loss: 0.0321 - val_accuracy: 0.9857 - val_loss: 0.0321\n",
            "Epoch 14/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.0318 - val_accuracy: 0.9850 - val_loss: 0.0360\n",
            "Epoch 15/15\n",
            "\u001b[1m12457/12457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0311 - val_accuracy: 0.9868 - val_loss: 0.0299\n",
            "\u001b[1m13841/13841\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step\n",
            "Classification Report for CICIDS2017:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97    108332\n",
            "           1       1.00      0.99      0.99    334562\n",
            "\n",
            "    accuracy                           0.99    442894\n",
            "   macro avg       0.98      0.99      0.98    442894\n",
            "weighted avg       0.99      0.99      0.99    442894\n",
            "\n",
            "Confusion Matrix:\n",
            " [[106884   1448]\n",
            " [  4264 330298]]\n",
            "\n",
            " Evaluation Metrics:\n",
            " Accuracy:  0.9871\n",
            "Precision: 0.9873\n",
            "Recall:    0.9871\n",
            "F1-Score:  0.9872\n",
            "AUC:       0.9993\n",
            "Avg FPR:   0.0131\n",
            "Avg TNR:   0.9869\n"
          ]
        }
      ]
    }
  ]
}